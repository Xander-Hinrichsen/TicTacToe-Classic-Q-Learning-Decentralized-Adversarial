{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToeEnvironment():\n",
    "    def __init__(self, mode='X'):\n",
    "        self.mode = mode\n",
    "        self.table = np.zeros((3,3), dtype=np.uint8)\n",
    "        self.observation_space = self.table.reshape(-1)\n",
    "    def checkwin(self):\n",
    "        for i in range(3):\n",
    "            if self.table[0,i] == self.table[1,i] and self.table[1,i] == self.table[2,i] and self.table[1,i] != 0:\n",
    "                return True, self.table[0,i]\n",
    "            if self.table[i, 0] == self.table[i,1] and self.table[i,1] == self.table[i,2] and self.table[i,1] != 0:\n",
    "                return True, self.table[i, 0]\n",
    "        if self.table[0,0] == self.table[1,1] and self.table[1,1] == self.table[2,2] and self.table[0,0] != 0:\n",
    "            return True, self.table[1,1]\n",
    "        if self.table[0,2] == self.table[1,1] and self.table[1,1] == self.table[2,0] and self.table[0,2] != 0:\n",
    "            return True, self.table[1,1]\n",
    "        return False, 0\n",
    "    def board_full(self):\n",
    "        return not 0 in self.table\n",
    "    def encode_table(self):\n",
    "        flat_table = self.table.reshape(-1)\n",
    "        encoding = ''\n",
    "        for i in range(len(flat_table)):\n",
    "            encoding += str(int(flat_table[i]))\n",
    "        return encoding\n",
    "    def observation(self):\n",
    "        return self.encode_table()\n",
    "    def reset(self):\n",
    "        self.table = np.zeros((3,3))\n",
    "        return self.encode_table()\n",
    "    def encoding_to_idx(self, encoding):\n",
    "        values = np.zeros(9)\n",
    "        for i in range(9):\n",
    "            values[i] = encoding[i]\n",
    "        return int(np.sum(values* 3**np.arange(9)))\n",
    "    def step(self, action, player):\n",
    "        if action < 0 or action  >= 9:\n",
    "            raise ValueError('action space an int in range [0,9)')\n",
    "        valid_move = False\n",
    "        to_place = 1 if player == 'X' else 2\n",
    "        if self.table[action // 3, action % 3] == 0:\n",
    "            self.table[action // 3, action % 3] = to_place\n",
    "            valid_move = True\n",
    "        is_win, winner_num = self.checkwin()\n",
    "        terminated = True if (is_win or self.board_full()) else False\n",
    "        if is_win and winner_num == to_place:\n",
    "            #print('player', player, 'won!')\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = 0\n",
    "        return self.encode_table(), reward, terminated, self.board_full()\n",
    "    def print_board(self):\n",
    "        char_table = np.array([[' ',' ',' '],[' ',' ',' '],[' ',' ',' ']])\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if self.table[i,j] == 1:\n",
    "                    char_table[i,j] = 'X'\n",
    "                elif self.table[i,j] == 2:\n",
    "                    char_table[i,j] = 'O'\n",
    "            \n",
    "        print(char_table[0,0], '|', char_table[0,1], '|', char_table[0,2])\n",
    "        print('---------')\n",
    "        print(char_table[1,0], '|', char_table[1,1], '|', char_table[1,2])\n",
    "        print('---------')\n",
    "        print(char_table[2,0], '|', char_table[2,1], '|', char_table[2,2])\n",
    "\n",
    "    def play_against_policy(self, policy, mode='X', deterministic=True):\n",
    "        player_piece = 1 if mode == 'X' else 2\n",
    "        ai_piece = 2 if mode == 'X' else 1\n",
    "        for i in range(9):\n",
    "            self.print_board()\n",
    "            if (mode == 'X' and (i % 2) == 0) or (mode == 'O' and (i % 2) == 1):\n",
    "                print('choose your move')\n",
    "                move = -1\n",
    "                while (move < 0 or move >= 9):\n",
    "                    move = int(input())\n",
    "                self.table[move // 3, move % 3] = player_piece\n",
    "            else:\n",
    "                print('press enter for ai move')\n",
    "                input()\n",
    "                if deterministic:\n",
    "                    ai_move = np.argmax(policy[self.encoding_to_idx(self.encode_table())])\n",
    "                ##sample from Q-values as if they were probability distribution\n",
    "                else:\n",
    "                    dist = policy[self.encoding_to_idx(self.encode_table())]\n",
    "                    #turn to probability distribution\n",
    "                    dist_probs = dist / np.sum(dist)\n",
    "                    ##sample the action\n",
    "                    ai_move = np.random.choice(np.arange(9), p=dist_probs)\n",
    "                self.table[ai_move // 3, ai_move % 3] = ai_piece\n",
    "            game_over, _ = self.checkwin()\n",
    "            if game_over:\n",
    "                break\n",
    "        self.print_board()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice([0,1], p=[0.5,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |   |  \n",
      "---------\n",
      "  |   |  \n",
      "---------\n",
      "  |   |  \n"
     ]
    }
   ],
   "source": [
    "env = TicTacToeEnvironment()\n",
    "env.print_board()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_to_idx(encoding):\n",
    "    values = np.zeros(9)\n",
    "    for i in range(9):\n",
    "        values[i] = encoding[i]\n",
    "    return int(np.sum(values* 3**np.arange(9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy(epsilon, player_table, string_state):\n",
    "    valid_indices = []\n",
    "    for i in range(9):\n",
    "        if string_state[i] == '0':\n",
    "            valid_indices.append(i)\n",
    "    if len(valid_indices) < 1:\n",
    "        raise ValueError('No valid board choices!?')\n",
    "    random_action = np.random.choice([True,False], p=[epsilon, (1-epsilon)])\n",
    "    if random_action:\n",
    "        return np.random.choice(valid_indices)\n",
    "    \n",
    "    valid_choices = player_table[encoding_to_idx(string_state)][valid_indices]\n",
    "    max_valid = valid_indices[np.argmax(valid_choices)]\n",
    "    return max_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_player, O_player, env, num_episodes, lr, epsilon_decay, gamma, start_decay):\n",
    "    x_wins_arr = []\n",
    "    o_wins_arr = []\n",
    "    ties_arr = []\n",
    "    x_wins = 0\n",
    "    o_wins = 0\n",
    "    ties = 0\n",
    "    players = [X_player, O_player]\n",
    "    epsilon = 1\n",
    "    for episode in range(num_episodes):\n",
    "        x_up_next_state = env.reset()\n",
    "        terminated = False\n",
    "        turn_num = 0\n",
    "        while (True):\n",
    "            \n",
    "            ##X action            \n",
    "            x_action = epsilon_greedy(epsilon, X_player, x_up_next_state)\n",
    "            x_just_played_state, x_reward, x_terminated, board_full = env.step(x_action, 'X')\n",
    "            \n",
    "            \n",
    "            ##bellman O update -> can't update on turn 0 yet, O hasn't played\n",
    "            if turn_num > 0:\n",
    "                O_player[env.encoding_to_idx(x_play_last_turn), o_action] += \\\n",
    "                lr * ((o_reward + gamma*np.max(O_player[env.encoding_to_idx(x_just_played_state)]) \\\n",
    "                       - O_player[env.encoding_to_idx(x_play_last_turn), o_action]))\n",
    "                \n",
    "                if o_terminated or board_full:\n",
    "                    o_wins+=o_reward\n",
    "                    if board_full and not o_reward:\n",
    "                        ties+=1\n",
    "                    break\n",
    "            x_play_last_turn = x_just_played_state\n",
    "            \n",
    "            ##O action\n",
    "            o_action = epsilon_greedy(epsilon, O_player, x_just_played_state)\n",
    "            o_just_played_state, o_reward, o_terminated, board_full = env.step(o_action, 'O')\n",
    "            \n",
    "\n",
    "            ##bellman X update\n",
    "            X_player[env.encoding_to_idx(x_up_next_state), x_action] += \\\n",
    "            lr * ((x_reward + gamma*np.max(X_player[env.encoding_to_idx(o_just_played_state)]) \\\n",
    "                   - X_player[env.encoding_to_idx(x_up_next_state), x_action]))\n",
    "            \n",
    "            if x_terminated or board_full:\n",
    "                x_wins+=x_reward\n",
    "                break\n",
    "        \n",
    "            x_up_next_state = o_just_played_state\n",
    "            turn_num += 1\n",
    "        if episode > start_decay:\n",
    "            epsilon = np.exp(-epsilon_decay * (episode - start_decay))\n",
    "        if ((episode + 1) % 10000) == 0:\n",
    "            print('Episode', episode + 1, 'done')\n",
    "            print(f'epsilon: {epsilon:.3f}')\n",
    "            print('X Wins:', x_wins)\n",
    "            print('O Wins:', o_wins)\n",
    "            print('Ties:', ties)\n",
    "            print()\n",
    "            x_wins_arr.append(x_wins)\n",
    "            o_wins_arr.append(o_wins)\n",
    "            ties_arr.append(ties)\n",
    "    return x_wins_arr, o_wins_arr, ties_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##policies\n",
    "X_player = np.zeros((3**9, 9))\n",
    "O_player = np.zeros((3**9, 9))\n",
    "\n",
    "##environment\n",
    "env = TicTacToeEnvironment()\n",
    "\n",
    "##hyperparams\n",
    "num_episodes = 1000000\n",
    "lr = 0.2\n",
    "gamma = 1\n",
    "start_decay = 300000\n",
    "epsilon_decay = 5 / (num_episodes - start_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 3556\n",
      "O Wins: 2871\n",
      "Ties: 3573\n",
      "\n",
      "Episode 20000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 7125\n",
      "O Wins: 5741\n",
      "Ties: 7134\n",
      "\n",
      "Episode 30000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 10670\n",
      "O Wins: 8656\n",
      "Ties: 10674\n",
      "\n",
      "Episode 40000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 14270\n",
      "O Wins: 11513\n",
      "Ties: 14217\n",
      "\n",
      "Episode 50000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 17818\n",
      "O Wins: 14412\n",
      "Ties: 17770\n",
      "\n",
      "Episode 60000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 21452\n",
      "O Wins: 17234\n",
      "Ties: 21314\n",
      "\n",
      "Episode 70000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 25003\n",
      "O Wins: 20112\n",
      "Ties: 24885\n",
      "\n",
      "Episode 80000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 28603\n",
      "O Wins: 23048\n",
      "Ties: 28349\n",
      "\n",
      "Episode 90000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 32225\n",
      "O Wins: 25926\n",
      "Ties: 31849\n",
      "\n",
      "Episode 100000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 35835\n",
      "O Wins: 28777\n",
      "Ties: 35388\n",
      "\n",
      "Episode 110000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 39392\n",
      "O Wins: 31689\n",
      "Ties: 38919\n",
      "\n",
      "Episode 120000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 42936\n",
      "O Wins: 34572\n",
      "Ties: 42492\n",
      "\n",
      "Episode 130000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 46570\n",
      "O Wins: 37478\n",
      "Ties: 45952\n",
      "\n",
      "Episode 140000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 50124\n",
      "O Wins: 40248\n",
      "Ties: 49628\n",
      "\n",
      "Episode 150000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 53733\n",
      "O Wins: 43077\n",
      "Ties: 53190\n",
      "\n",
      "Episode 160000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 57261\n",
      "O Wins: 45993\n",
      "Ties: 56746\n",
      "\n",
      "Episode 170000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 60826\n",
      "O Wins: 48931\n",
      "Ties: 60243\n",
      "\n",
      "Episode 180000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 64414\n",
      "O Wins: 51776\n",
      "Ties: 63810\n",
      "\n",
      "Episode 190000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 67945\n",
      "O Wins: 54672\n",
      "Ties: 67383\n",
      "\n",
      "Episode 200000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 71518\n",
      "O Wins: 57529\n",
      "Ties: 70953\n",
      "\n",
      "Episode 210000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 75051\n",
      "O Wins: 60457\n",
      "Ties: 74492\n",
      "\n",
      "Episode 220000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 78719\n",
      "O Wins: 63303\n",
      "Ties: 77978\n",
      "\n",
      "Episode 230000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 82310\n",
      "O Wins: 66139\n",
      "Ties: 81551\n",
      "\n",
      "Episode 240000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 86006\n",
      "O Wins: 68916\n",
      "Ties: 85078\n",
      "\n",
      "Episode 250000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 89524\n",
      "O Wins: 71835\n",
      "Ties: 88641\n",
      "\n",
      "Episode 260000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 93063\n",
      "O Wins: 74706\n",
      "Ties: 92231\n",
      "\n",
      "Episode 270000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 96763\n",
      "O Wins: 77614\n",
      "Ties: 95623\n",
      "\n",
      "Episode 280000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 100332\n",
      "O Wins: 80478\n",
      "Ties: 99190\n",
      "\n",
      "Episode 290000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 103940\n",
      "O Wins: 83340\n",
      "Ties: 102720\n",
      "\n",
      "Episode 300000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 107638\n",
      "O Wins: 86204\n",
      "Ties: 106158\n",
      "\n",
      "Episode 310000 done\n",
      "epsilon: 0.931\n",
      "X Wins: 111402\n",
      "O Wins: 89159\n",
      "Ties: 109439\n",
      "\n",
      "Episode 320000 done\n",
      "epsilon: 0.867\n",
      "X Wins: 115466\n",
      "O Wins: 92201\n",
      "Ties: 112333\n",
      "\n",
      "Episode 330000 done\n",
      "epsilon: 0.807\n",
      "X Wins: 119739\n",
      "O Wins: 95361\n",
      "Ties: 114900\n",
      "\n",
      "Episode 340000 done\n",
      "epsilon: 0.751\n",
      "X Wins: 124274\n",
      "O Wins: 98615\n",
      "Ties: 117111\n",
      "\n",
      "Episode 350000 done\n",
      "epsilon: 0.700\n",
      "X Wins: 129074\n",
      "O Wins: 101886\n",
      "Ties: 119040\n",
      "\n",
      "Episode 360000 done\n",
      "epsilon: 0.651\n",
      "X Wins: 134064\n",
      "O Wins: 105088\n",
      "Ties: 120848\n",
      "\n",
      "Episode 370000 done\n",
      "epsilon: 0.607\n",
      "X Wins: 139195\n",
      "O Wins: 108243\n",
      "Ties: 122562\n",
      "\n",
      "Episode 380000 done\n",
      "epsilon: 0.565\n",
      "X Wins: 144321\n",
      "O Wins: 111601\n",
      "Ties: 124078\n",
      "\n",
      "Episode 390000 done\n",
      "epsilon: 0.526\n",
      "X Wins: 149599\n",
      "O Wins: 114916\n",
      "Ties: 125485\n",
      "\n",
      "Episode 400000 done\n",
      "epsilon: 0.490\n",
      "X Wins: 155099\n",
      "O Wins: 118162\n",
      "Ties: 126739\n",
      "\n",
      "Episode 410000 done\n",
      "epsilon: 0.456\n",
      "X Wins: 160792\n",
      "O Wins: 121246\n",
      "Ties: 127962\n",
      "\n",
      "Episode 420000 done\n",
      "epsilon: 0.424\n",
      "X Wins: 166371\n",
      "O Wins: 124503\n",
      "Ties: 129126\n",
      "\n",
      "Episode 430000 done\n",
      "epsilon: 0.395\n",
      "X Wins: 172160\n",
      "O Wins: 127669\n",
      "Ties: 130171\n",
      "\n",
      "Episode 440000 done\n",
      "epsilon: 0.368\n",
      "X Wins: 178220\n",
      "O Wins: 130630\n",
      "Ties: 131150\n",
      "\n",
      "Episode 450000 done\n",
      "epsilon: 0.343\n",
      "X Wins: 184377\n",
      "O Wins: 133526\n",
      "Ties: 132097\n",
      "\n",
      "Episode 460000 done\n",
      "epsilon: 0.319\n",
      "X Wins: 190707\n",
      "O Wins: 136258\n",
      "Ties: 133035\n",
      "\n",
      "Episode 470000 done\n",
      "epsilon: 0.297\n",
      "X Wins: 197162\n",
      "O Wins: 139031\n",
      "Ties: 133807\n",
      "\n",
      "Episode 480000 done\n",
      "epsilon: 0.276\n",
      "X Wins: 203923\n",
      "O Wins: 141584\n",
      "Ties: 134493\n",
      "\n",
      "Episode 490000 done\n",
      "epsilon: 0.257\n",
      "X Wins: 210826\n",
      "O Wins: 144075\n",
      "Ties: 135099\n",
      "\n",
      "Episode 500000 done\n",
      "epsilon: 0.240\n",
      "X Wins: 217867\n",
      "O Wins: 146452\n",
      "Ties: 135681\n",
      "\n",
      "Episode 510000 done\n",
      "epsilon: 0.223\n",
      "X Wins: 224980\n",
      "O Wins: 148718\n",
      "Ties: 136302\n",
      "\n",
      "Episode 520000 done\n",
      "epsilon: 0.208\n",
      "X Wins: 232219\n",
      "O Wins: 150870\n",
      "Ties: 136911\n",
      "\n",
      "Episode 530000 done\n",
      "epsilon: 0.193\n",
      "X Wins: 239580\n",
      "O Wins: 152929\n",
      "Ties: 137491\n",
      "\n",
      "Episode 540000 done\n",
      "epsilon: 0.180\n",
      "X Wins: 247219\n",
      "O Wins: 154751\n",
      "Ties: 138030\n",
      "\n",
      "Episode 550000 done\n",
      "epsilon: 0.168\n",
      "X Wins: 254911\n",
      "O Wins: 156558\n",
      "Ties: 138531\n",
      "\n",
      "Episode 560000 done\n",
      "epsilon: 0.156\n",
      "X Wins: 262583\n",
      "O Wins: 158378\n",
      "Ties: 139039\n",
      "\n",
      "Episode 570000 done\n",
      "epsilon: 0.145\n",
      "X Wins: 270641\n",
      "O Wins: 159954\n",
      "Ties: 139405\n",
      "\n",
      "Episode 580000 done\n",
      "epsilon: 0.135\n",
      "X Wins: 278799\n",
      "O Wins: 161371\n",
      "Ties: 139830\n",
      "\n",
      "Episode 590000 done\n",
      "epsilon: 0.126\n",
      "X Wins: 286911\n",
      "O Wins: 162915\n",
      "Ties: 140174\n",
      "\n",
      "Episode 600000 done\n",
      "epsilon: 0.117\n",
      "X Wins: 295169\n",
      "O Wins: 164331\n",
      "Ties: 140500\n",
      "\n",
      "Episode 610000 done\n",
      "epsilon: 0.109\n",
      "X Wins: 303429\n",
      "O Wins: 165810\n",
      "Ties: 140761\n",
      "\n",
      "Episode 620000 done\n",
      "epsilon: 0.102\n",
      "X Wins: 311775\n",
      "O Wins: 167181\n",
      "Ties: 141044\n",
      "\n",
      "Episode 630000 done\n",
      "epsilon: 0.095\n",
      "X Wins: 320249\n",
      "O Wins: 168414\n",
      "Ties: 141337\n",
      "\n",
      "Episode 640000 done\n",
      "epsilon: 0.088\n",
      "X Wins: 328559\n",
      "O Wins: 169813\n",
      "Ties: 141628\n",
      "\n",
      "Episode 650000 done\n",
      "epsilon: 0.082\n",
      "X Wins: 337094\n",
      "O Wins: 171056\n",
      "Ties: 141850\n",
      "\n",
      "Episode 660000 done\n",
      "epsilon: 0.076\n",
      "X Wins: 345778\n",
      "O Wins: 172113\n",
      "Ties: 142109\n",
      "\n",
      "Episode 670000 done\n",
      "epsilon: 0.071\n",
      "X Wins: 354433\n",
      "O Wins: 173204\n",
      "Ties: 142363\n",
      "\n",
      "Episode 680000 done\n",
      "epsilon: 0.066\n",
      "X Wins: 363303\n",
      "O Wins: 174132\n",
      "Ties: 142565\n",
      "\n",
      "Episode 690000 done\n",
      "epsilon: 0.062\n",
      "X Wins: 372236\n",
      "O Wins: 174966\n",
      "Ties: 142798\n",
      "\n",
      "Episode 700000 done\n",
      "epsilon: 0.057\n",
      "X Wins: 381273\n",
      "O Wins: 175651\n",
      "Ties: 143076\n",
      "\n",
      "Episode 710000 done\n",
      "epsilon: 0.053\n",
      "X Wins: 390565\n",
      "O Wins: 176250\n",
      "Ties: 143185\n",
      "\n",
      "Episode 720000 done\n",
      "epsilon: 0.050\n",
      "X Wins: 399776\n",
      "O Wins: 176862\n",
      "Ties: 143362\n",
      "\n",
      "Episode 730000 done\n",
      "epsilon: 0.046\n",
      "X Wins: 408936\n",
      "O Wins: 177546\n",
      "Ties: 143518\n",
      "\n",
      "Episode 740000 done\n",
      "epsilon: 0.043\n",
      "X Wins: 418237\n",
      "O Wins: 178155\n",
      "Ties: 143608\n",
      "\n",
      "Episode 750000 done\n",
      "epsilon: 0.040\n",
      "X Wins: 427666\n",
      "O Wins: 178666\n",
      "Ties: 143668\n",
      "\n",
      "Episode 760000 done\n",
      "epsilon: 0.037\n",
      "X Wins: 436981\n",
      "O Wins: 179234\n",
      "Ties: 143785\n",
      "\n",
      "Episode 770000 done\n",
      "epsilon: 0.035\n",
      "X Wins: 446286\n",
      "O Wins: 179772\n",
      "Ties: 143942\n",
      "\n",
      "Episode 780000 done\n",
      "epsilon: 0.032\n",
      "X Wins: 455815\n",
      "O Wins: 180189\n",
      "Ties: 143996\n",
      "\n",
      "Episode 790000 done\n",
      "epsilon: 0.030\n",
      "X Wins: 465285\n",
      "O Wins: 180678\n",
      "Ties: 144037\n",
      "\n",
      "Episode 800000 done\n",
      "epsilon: 0.028\n",
      "X Wins: 474732\n",
      "O Wins: 181154\n",
      "Ties: 144114\n",
      "\n",
      "Episode 810000 done\n",
      "epsilon: 0.026\n",
      "X Wins: 484234\n",
      "O Wins: 181633\n",
      "Ties: 144133\n",
      "\n",
      "Episode 820000 done\n",
      "epsilon: 0.024\n",
      "X Wins: 493753\n",
      "O Wins: 182091\n",
      "Ties: 144156\n",
      "\n",
      "Episode 830000 done\n",
      "epsilon: 0.023\n",
      "X Wins: 503364\n",
      "O Wins: 182440\n",
      "Ties: 144196\n",
      "\n",
      "Episode 840000 done\n",
      "epsilon: 0.021\n",
      "X Wins: 512994\n",
      "O Wins: 182743\n",
      "Ties: 144263\n",
      "\n",
      "Episode 850000 done\n",
      "epsilon: 0.020\n",
      "X Wins: 522570\n",
      "O Wins: 183114\n",
      "Ties: 144316\n",
      "\n",
      "Episode 860000 done\n",
      "epsilon: 0.018\n",
      "X Wins: 532256\n",
      "O Wins: 183391\n",
      "Ties: 144353\n",
      "\n",
      "Episode 870000 done\n",
      "epsilon: 0.017\n",
      "X Wins: 542025\n",
      "O Wins: 183600\n",
      "Ties: 144375\n",
      "\n",
      "Episode 880000 done\n",
      "epsilon: 0.016\n",
      "X Wins: 551724\n",
      "O Wins: 183852\n",
      "Ties: 144424\n",
      "\n",
      "Episode 890000 done\n",
      "epsilon: 0.015\n",
      "X Wins: 561408\n",
      "O Wins: 184115\n",
      "Ties: 144477\n",
      "\n",
      "Episode 900000 done\n",
      "epsilon: 0.014\n",
      "X Wins: 571157\n",
      "O Wins: 184322\n",
      "Ties: 144521\n",
      "\n",
      "Episode 910000 done\n",
      "epsilon: 0.013\n",
      "X Wins: 580882\n",
      "O Wins: 184570\n",
      "Ties: 144548\n",
      "\n",
      "Episode 920000 done\n",
      "epsilon: 0.012\n",
      "X Wins: 590646\n",
      "O Wins: 184748\n",
      "Ties: 144606\n",
      "\n",
      "Episode 930000 done\n",
      "epsilon: 0.011\n",
      "X Wins: 600390\n",
      "O Wins: 184965\n",
      "Ties: 144645\n",
      "\n",
      "Episode 940000 done\n",
      "epsilon: 0.010\n",
      "X Wins: 610197\n",
      "O Wins: 185131\n",
      "Ties: 144672\n",
      "\n",
      "Episode 950000 done\n",
      "epsilon: 0.010\n",
      "X Wins: 619981\n",
      "O Wins: 185314\n",
      "Ties: 144705\n",
      "\n",
      "Episode 960000 done\n",
      "epsilon: 0.009\n",
      "X Wins: 629784\n",
      "O Wins: 185471\n",
      "Ties: 144745\n",
      "\n",
      "Episode 970000 done\n",
      "epsilon: 0.008\n",
      "X Wins: 639634\n",
      "O Wins: 185601\n",
      "Ties: 144765\n",
      "\n",
      "Episode 980000 done\n",
      "epsilon: 0.008\n",
      "X Wins: 649508\n",
      "O Wins: 185705\n",
      "Ties: 144787\n",
      "\n",
      "Episode 990000 done\n",
      "epsilon: 0.007\n",
      "X Wins: 659410\n",
      "O Wins: 185789\n",
      "Ties: 144801\n",
      "\n",
      "Episode 1000000 done\n",
      "epsilon: 0.007\n",
      "X Wins: 669323\n",
      "O Wins: 185865\n",
      "Ties: 144812\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(X_player, O_player, env, num_episodes, lr, epsilon_decay, gamma, start_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env = TicTacToeEnvironment()\n",
    "state = test_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##policies\n",
    "# X_player = np.zeros((3**9, 9))\n",
    "# O_player = np.zeros((3**9, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |   |  \n",
      "---------\n",
      "  |   |  \n",
      "---------\n",
      "  |   |  \n",
      "choose your move\n",
      "2\n",
      "  |   | X\n",
      "---------\n",
      "  |   |  \n",
      "---------\n",
      "  |   |  \n",
      "press enter for ai move\n",
      "\n",
      "  |   | X\n",
      "---------\n",
      "  | O |  \n",
      "---------\n",
      "  |   |  \n",
      "choose your move\n",
      "0\n",
      "X |   | X\n",
      "---------\n",
      "  | O |  \n",
      "---------\n",
      "  |   |  \n",
      "press enter for ai move\n",
      "\n",
      "X | O | X\n",
      "---------\n",
      "  | O |  \n",
      "---------\n",
      "  |   |  \n",
      "choose your move\n",
      "8\n",
      "X | O | X\n",
      "---------\n",
      "  | O |  \n",
      "---------\n",
      "  |   | X\n",
      "press enter for ai move\n",
      "\n",
      "X | O | X\n",
      "---------\n",
      "  | O |  \n",
      "---------\n",
      "  | O | X\n"
     ]
    }
   ],
   "source": [
    "test_env.reset()\n",
    "test_env.play_against_policy(O_player, mode='X', deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |   |  \n",
      "---------\n",
      "  |   |  \n",
      "---------\n",
      "  |   |  \n",
      "press enter for ai move\n",
      "\n",
      "  |   |  \n",
      "---------\n",
      "  | X |  \n",
      "---------\n",
      "  |   |  \n"
     ]
    }
   ],
   "source": [
    "test_env.reset()\n",
    "test_env.play_against_policy(X_player, mode='O', deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999998"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(O_player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(O_player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(X_player[encoding_to_idx('0100111100')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_to_idx('100000000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O_player[encoding_to_idx('01000001111')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1347"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(O_player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 1.        , 0.        , 0.99999999])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_player[encoding_to_idx('121212000')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_player[encoding_to_idx('121212100')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 1.        , 0.        , 0.99999999])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_player[encoding_to_idx('121212000')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

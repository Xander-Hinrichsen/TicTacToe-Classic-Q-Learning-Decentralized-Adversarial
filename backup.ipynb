{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToeEnvironment():\n",
    "    def __init__(self, mode='X', points_for_tie=False):\n",
    "        self.mode = mode\n",
    "        self.table = np.zeros((3,3), dtype=np.uint8)\n",
    "        self.observation_space = self.table.reshape(-1)\n",
    "        self.points_for_tie = False\n",
    "    def checkwin(self):\n",
    "        for i in range(3):\n",
    "            if self.table[0,i] == self.table[1,i] and self.table[1,i] == self.table[2,i] and self.table[1,i] != 0:\n",
    "                return True, self.table[0,i]\n",
    "            if self.table[i, 0] == self.table[i,1] and self.table[i,1] == self.table[i,2] and self.table[i,1] != 0:\n",
    "                return True, self.table[i, 0]\n",
    "        if self.table[0,0] == self.table[1,1] and self.table[1,1] == self.table[2,2] and self.table[0,0] != 0:\n",
    "            return True, self.table[1,1]\n",
    "        if self.table[0,2] == self.table[1,1] and self.table[1,1] == self.table[2,0] and self.table[0,2] != 0:\n",
    "            return True, self.table[1,1]\n",
    "        return False, 0\n",
    "    def board_full(self):\n",
    "        return not 0 in self.table\n",
    "    def encode_table(self):\n",
    "        flat_table = self.table.reshape(-1)\n",
    "        encoding = ''\n",
    "        for i in range(len(flat_table)):\n",
    "            encoding += str(int(flat_table[i]))\n",
    "        return encoding\n",
    "    def observation(self):\n",
    "        return self.encode_table()\n",
    "    def reset(self):\n",
    "        self.table = np.zeros((3,3))\n",
    "        return self.encode_table()\n",
    "    def encoding_to_idx(self, encoding):\n",
    "        values = np.zeros(9)\n",
    "        for i in range(9):\n",
    "            values[i] = encoding[i]\n",
    "        return int(np.sum(values* 3**np.arange(9)))\n",
    "    def step(self, action, player):\n",
    "        if action < 0 or action  >= 9:\n",
    "            raise ValueError('action space an int in range [0,9)')\n",
    "        valid_move = False\n",
    "        to_place = 1 if player == 'X' else 2\n",
    "        if self.table[action // 3, action % 3] == 0:\n",
    "            self.table[action // 3, action % 3] = to_place\n",
    "            valid_move = True\n",
    "        is_win, winner_num = self.checkwin()\n",
    "        board_full = self.bloard_full()\n",
    "        terminated = True if (is_win or board_full) else False\n",
    "        if is_win and winner_num == to_place:\n",
    "            #print('player', player, 'won!')\n",
    "            reward = 1\n",
    "        else if winner_num == 2 and board_full and self.points_for_tie:\n",
    "            reward = 0.5\n",
    "        else:\n",
    "            reward = 0\n",
    "        return self.encode_table(), reward, terminated, board_full\n",
    "    def print_board(self):\n",
    "        char_table = np.array([[' ',' ',' '],[' ',' ',' '],[' ',' ',' ']])\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if self.table[i,j] == 1:\n",
    "                    char_table[i,j] = 'X'\n",
    "                elif self.table[i,j] == 2:\n",
    "                    char_table[i,j] = 'O'\n",
    "            \n",
    "        print(char_table[0,0], '|', char_table[0,1], '|', char_table[0,2])\n",
    "        print('---------')\n",
    "        print(char_table[1,0], '|', char_table[1,1], '|', char_table[1,2])\n",
    "        print('---------')\n",
    "        print(char_table[2,0], '|', char_table[2,1], '|', char_table[2,2])\n",
    "\n",
    "    def play_against_policy(self, policy, mode='X', deterministic=True):\n",
    "        player_piece = 1 if mode == 'X' else 2\n",
    "        ai_piece = 2 if mode == 'X' else 1\n",
    "        for i in range(9):\n",
    "            self.print_board()\n",
    "            if (mode == 'X' and (i % 2) == 0) or (mode == 'O' and (i % 2) == 1):\n",
    "                print('choose your move')\n",
    "                move = -1\n",
    "                while (move < 0 or move >= 9):\n",
    "                    move = int(input())\n",
    "                self.table[move // 3, move % 3] = player_piece\n",
    "            else:\n",
    "                print('press enter for ai move')\n",
    "                input()\n",
    "                if deterministic:\n",
    "                    ai_move = np.argmax(policy[self.encoding_to_idx(self.encode_table())])\n",
    "                ##sample from Q-values as if they were probability distribution\n",
    "                else:\n",
    "                    dist = policy[self.encoding_to_idx(self.encode_table())]\n",
    "                    #turn to probability distribution\n",
    "                    dist_probs = dist / np.sum(dist)\n",
    "                    ##sample the action\n",
    "                    ai_move = np.random.choice(np.arange(9), p=dist_probs)\n",
    "                self.table[ai_move // 3, ai_move % 3] = ai_piece\n",
    "            game_over, _ = self.checkwin()\n",
    "            if game_over:\n",
    "                break\n",
    "        self.print_board()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice([0,1], p=[0.5,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |   |  \n",
      "---------\n",
      "  |   |  \n",
      "---------\n",
      "  |   |  \n"
     ]
    }
   ],
   "source": [
    "env = TicTacToeEnvironment()\n",
    "env.print_board()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_to_idx(encoding):\n",
    "    values = np.zeros(9)\n",
    "    for i in range(9):\n",
    "        values[i] = encoding[i]\n",
    "    return int(np.sum(values* 3**np.arange(9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy(epsilon, player_table, string_state):\n",
    "    valid_indices = []\n",
    "    for i in range(9):\n",
    "        if string_state[i] == '0':\n",
    "            valid_indices.append(i)\n",
    "    if len(valid_indices) < 1:\n",
    "        raise ValueError('No valid board choices!?')\n",
    "    random_action = np.random.choice([True,False], p=[epsilon, (1-epsilon)])\n",
    "    if random_action:\n",
    "        return np.random.choice(valid_indices)\n",
    "    \n",
    "    valid_choices = player_table[encoding_to_idx(string_state)][valid_indices]\n",
    "    max_valid = valid_indices[np.argmax(valid_choices)]\n",
    "    return max_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_player, O_player, env, num_episodes, lr, epsilon_decay, gamma, start_decay):\n",
    "    x_wins_arr = []\n",
    "    o_wins_arr = []\n",
    "    ties_arr = []\n",
    "    x_wins = 0\n",
    "    o_wins = 0\n",
    "    ties = 0\n",
    "    players = [X_player, O_player]\n",
    "    epsilon = 1\n",
    "    for episode in range(num_episodes):\n",
    "        x_up_next_state = env.reset()\n",
    "        terminated = False\n",
    "        turn_num = 0\n",
    "        while (True):\n",
    "            \n",
    "            ##X action            \n",
    "            x_action = epsilon_greedy(epsilon, X_player, x_up_next_state)\n",
    "            x_just_played_state, x_reward, x_terminated, board_full = env.step(x_action, 'X')\n",
    "            \n",
    "            \n",
    "            ##bellman O update -> can't update on turn 0 yet, O hasn't played\n",
    "            if turn_num > 0:\n",
    "                O_player[env.encoding_to_idx(x_play_last_turn), o_action] += \\\n",
    "                lr * ((o_reward + gamma*np.max(O_player[env.encoding_to_idx(x_just_played_state)]) \\\n",
    "                       - O_player[env.encoding_to_idx(x_play_last_turn), o_action]))\n",
    "                \n",
    "                if o_terminated or board_full:\n",
    "                    o_wins+= 1 if o_reward == 1 else 0\n",
    "                    if board_full and not o_reward:\n",
    "                        ties+=1\n",
    "                    break\n",
    "            x_play_last_turn = x_just_played_state\n",
    "            \n",
    "            ##O action\n",
    "            o_action = epsilon_greedy(epsilon, O_player, x_just_played_state)\n",
    "            o_just_played_state, o_reward, o_terminated, board_full = env.step(o_action, 'O')\n",
    "            \n",
    "\n",
    "            ##bellman X update\n",
    "            X_player[env.encoding_to_idx(x_up_next_state), x_action] += \\\n",
    "            lr * ((x_reward + gamma*np.max(X_player[env.encoding_to_idx(o_just_played_state)]) \\\n",
    "                   - X_player[env.encoding_to_idx(x_up_next_state), x_action]))\n",
    "            \n",
    "            if x_terminated or board_full:\n",
    "                x_wins+= 1 if x_reward == 1 else 0\n",
    "                break\n",
    "        \n",
    "            x_up_next_state = o_just_played_state\n",
    "            turn_num += 1\n",
    "        if episode > start_decay:\n",
    "            epsilon = np.exp(-epsilon_decay * (episode - start_decay))\n",
    "        if ((episode + 1) % 10000) == 0:\n",
    "            print('Episode', episode + 1, 'done')\n",
    "            print(f'epsilon: {epsilon:.3f}')\n",
    "            print('X Wins:', x_wins)\n",
    "            print('O Wins:', o_wins)\n",
    "            print('Ties:', ties)\n",
    "            print()\n",
    "            x_wins_arr.append(x_wins)\n",
    "            o_wins_arr.append(o_wins)\n",
    "            ties_arr.append(ties)\n",
    "    return x_wins_arr, o_wins_arr, ties_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##policies\n",
    "X_player = np.zeros((3**9, 9))\n",
    "O_player = np.zeros((3**9, 9))\n",
    "\n",
    "##environment\n",
    "env = TicTacToeEnvironment()\n",
    "\n",
    "##hyperparams\n",
    "num_episodes = 1000000\n",
    "lr = 0.2\n",
    "gamma = 1\n",
    "start_decay = 300000\n",
    "epsilon_decay = 5 / (num_episodes - start_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 3500\n",
      "O Wins: 2896\n",
      "Ties: 3604\n",
      "\n",
      "Episode 20000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 7119\n",
      "O Wins: 5817\n",
      "Ties: 7064\n",
      "\n",
      "Episode 30000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 10664\n",
      "O Wins: 8665\n",
      "Ties: 10671\n",
      "\n",
      "Episode 40000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 14366\n",
      "O Wins: 11526\n",
      "Ties: 14108\n",
      "\n",
      "Episode 50000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 17897\n",
      "O Wins: 14391\n",
      "Ties: 17712\n",
      "\n",
      "Episode 60000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 21445\n",
      "O Wins: 17237\n",
      "Ties: 21318\n",
      "\n",
      "Episode 70000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 25012\n",
      "O Wins: 20161\n",
      "Ties: 24827\n",
      "\n",
      "Episode 80000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 28558\n",
      "O Wins: 23068\n",
      "Ties: 28374\n",
      "\n",
      "Episode 90000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 32132\n",
      "O Wins: 26028\n",
      "Ties: 31840\n",
      "\n",
      "Episode 100000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 35719\n",
      "O Wins: 28923\n",
      "Ties: 35358\n",
      "\n",
      "Episode 110000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 39259\n",
      "O Wins: 31791\n",
      "Ties: 38950\n",
      "\n",
      "Episode 120000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 42792\n",
      "O Wins: 34692\n",
      "Ties: 42516\n",
      "\n",
      "Episode 130000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 46413\n",
      "O Wins: 37584\n",
      "Ties: 46003\n",
      "\n",
      "Episode 140000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 50082\n",
      "O Wins: 40478\n",
      "Ties: 49440\n",
      "\n",
      "Episode 150000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 53734\n",
      "O Wins: 43305\n",
      "Ties: 52961\n",
      "\n",
      "Episode 160000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 57348\n",
      "O Wins: 46120\n",
      "Ties: 56532\n",
      "\n",
      "Episode 170000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 61040\n",
      "O Wins: 48999\n",
      "Ties: 59961\n",
      "\n",
      "Episode 180000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 64627\n",
      "O Wins: 51880\n",
      "Ties: 63493\n",
      "\n",
      "Episode 190000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 68213\n",
      "O Wins: 54775\n",
      "Ties: 67012\n",
      "\n",
      "Episode 200000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 71856\n",
      "O Wins: 57604\n",
      "Ties: 70540\n",
      "\n",
      "Episode 210000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 75499\n",
      "O Wins: 60385\n",
      "Ties: 74116\n",
      "\n",
      "Episode 220000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 79105\n",
      "O Wins: 63303\n",
      "Ties: 77592\n",
      "\n",
      "Episode 230000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 82692\n",
      "O Wins: 66204\n",
      "Ties: 81104\n",
      "\n",
      "Episode 240000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 86319\n",
      "O Wins: 69062\n",
      "Ties: 84619\n",
      "\n",
      "Episode 250000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 90009\n",
      "O Wins: 71959\n",
      "Ties: 88032\n",
      "\n",
      "Episode 260000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 93589\n",
      "O Wins: 74824\n",
      "Ties: 91587\n",
      "\n",
      "Episode 270000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 97170\n",
      "O Wins: 77738\n",
      "Ties: 95092\n",
      "\n",
      "Episode 280000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 100707\n",
      "O Wins: 80624\n",
      "Ties: 98669\n",
      "\n",
      "Episode 290000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 104277\n",
      "O Wins: 83484\n",
      "Ties: 102239\n",
      "\n",
      "Episode 300000 done\n",
      "epsilon: 1.000\n",
      "X Wins: 107895\n",
      "O Wins: 86326\n",
      "Ties: 105779\n",
      "\n",
      "Episode 310000 done\n",
      "epsilon: 0.931\n",
      "X Wins: 111653\n",
      "O Wins: 89220\n",
      "Ties: 109127\n",
      "\n",
      "Episode 320000 done\n",
      "epsilon: 0.867\n",
      "X Wins: 115744\n",
      "O Wins: 92286\n",
      "Ties: 111970\n",
      "\n",
      "Episode 330000 done\n",
      "epsilon: 0.807\n",
      "X Wins: 120183\n",
      "O Wins: 95381\n",
      "Ties: 114436\n",
      "\n",
      "Episode 340000 done\n",
      "epsilon: 0.751\n",
      "X Wins: 124700\n",
      "O Wins: 98571\n",
      "Ties: 116729\n",
      "\n",
      "Episode 350000 done\n",
      "epsilon: 0.700\n",
      "X Wins: 129428\n",
      "O Wins: 101818\n",
      "Ties: 118754\n",
      "\n",
      "Episode 360000 done\n",
      "epsilon: 0.651\n",
      "X Wins: 134238\n",
      "O Wins: 105174\n",
      "Ties: 120588\n",
      "\n",
      "Episode 370000 done\n",
      "epsilon: 0.607\n",
      "X Wins: 139214\n",
      "O Wins: 108468\n",
      "Ties: 122318\n",
      "\n",
      "Episode 380000 done\n",
      "epsilon: 0.565\n",
      "X Wins: 144437\n",
      "O Wins: 111689\n",
      "Ties: 123874\n",
      "\n",
      "Episode 390000 done\n",
      "epsilon: 0.526\n",
      "X Wins: 149939\n",
      "O Wins: 114740\n",
      "Ties: 125321\n",
      "\n",
      "Episode 400000 done\n",
      "epsilon: 0.490\n",
      "X Wins: 155387\n",
      "O Wins: 117925\n",
      "Ties: 126688\n",
      "\n",
      "Episode 410000 done\n",
      "epsilon: 0.456\n",
      "X Wins: 160913\n",
      "O Wins: 121168\n",
      "Ties: 127919\n",
      "\n",
      "Episode 420000 done\n",
      "epsilon: 0.424\n",
      "X Wins: 166534\n",
      "O Wins: 124352\n",
      "Ties: 129114\n",
      "\n",
      "Episode 430000 done\n",
      "epsilon: 0.395\n",
      "X Wins: 172478\n",
      "O Wins: 127240\n",
      "Ties: 130282\n",
      "\n",
      "Episode 440000 done\n",
      "epsilon: 0.368\n",
      "X Wins: 178486\n",
      "O Wins: 130129\n",
      "Ties: 131385\n",
      "\n",
      "Episode 450000 done\n",
      "epsilon: 0.343\n",
      "X Wins: 184680\n",
      "O Wins: 132973\n",
      "Ties: 132347\n",
      "\n",
      "Episode 460000 done\n",
      "epsilon: 0.319\n",
      "X Wins: 191028\n",
      "O Wins: 135695\n",
      "Ties: 133277\n",
      "\n",
      "Episode 470000 done\n",
      "epsilon: 0.297\n",
      "X Wins: 197396\n",
      "O Wins: 138550\n",
      "Ties: 134054\n",
      "\n",
      "Episode 480000 done\n",
      "epsilon: 0.276\n",
      "X Wins: 204061\n",
      "O Wins: 141052\n",
      "Ties: 134887\n",
      "\n",
      "Episode 490000 done\n",
      "epsilon: 0.257\n",
      "X Wins: 210893\n",
      "O Wins: 143438\n",
      "Ties: 135669\n",
      "\n",
      "Episode 500000 done\n",
      "epsilon: 0.240\n",
      "X Wins: 217767\n",
      "O Wins: 145750\n",
      "Ties: 136483\n",
      "\n",
      "Episode 510000 done\n",
      "epsilon: 0.223\n",
      "X Wins: 224500\n",
      "O Wins: 148225\n",
      "Ties: 137275\n",
      "\n",
      "Episode 520000 done\n",
      "epsilon: 0.208\n",
      "X Wins: 231799\n",
      "O Wins: 150362\n",
      "Ties: 137839\n",
      "\n",
      "Episode 530000 done\n",
      "epsilon: 0.193\n",
      "X Wins: 238933\n",
      "O Wins: 152628\n",
      "Ties: 138439\n",
      "\n",
      "Episode 540000 done\n",
      "epsilon: 0.180\n",
      "X Wins: 246433\n",
      "O Wins: 154580\n",
      "Ties: 138987\n",
      "\n",
      "Episode 550000 done\n",
      "epsilon: 0.168\n",
      "X Wins: 254102\n",
      "O Wins: 156463\n",
      "Ties: 139435\n",
      "\n",
      "Episode 560000 done\n",
      "epsilon: 0.156\n",
      "X Wins: 261816\n",
      "O Wins: 158344\n",
      "Ties: 139840\n",
      "\n",
      "Episode 570000 done\n",
      "epsilon: 0.145\n",
      "X Wins: 269602\n",
      "O Wins: 160166\n",
      "Ties: 140232\n",
      "\n",
      "Episode 580000 done\n",
      "epsilon: 0.135\n",
      "X Wins: 277618\n",
      "O Wins: 161767\n",
      "Ties: 140615\n",
      "\n",
      "Episode 590000 done\n",
      "epsilon: 0.126\n",
      "X Wins: 285496\n",
      "O Wins: 163437\n",
      "Ties: 141067\n",
      "\n",
      "Episode 600000 done\n",
      "epsilon: 0.117\n",
      "X Wins: 293594\n",
      "O Wins: 164887\n",
      "Ties: 141519\n",
      "\n",
      "Episode 610000 done\n",
      "epsilon: 0.109\n",
      "X Wins: 301858\n",
      "O Wins: 166356\n",
      "Ties: 141786\n",
      "\n",
      "Episode 620000 done\n",
      "epsilon: 0.102\n",
      "X Wins: 310180\n",
      "O Wins: 167826\n",
      "Ties: 141994\n",
      "\n",
      "Episode 630000 done\n",
      "epsilon: 0.095\n",
      "X Wins: 318528\n",
      "O Wins: 169140\n",
      "Ties: 142332\n",
      "\n",
      "Episode 640000 done\n",
      "epsilon: 0.088\n",
      "X Wins: 326951\n",
      "O Wins: 170526\n",
      "Ties: 142523\n",
      "\n",
      "Episode 650000 done\n",
      "epsilon: 0.082\n",
      "X Wins: 335592\n",
      "O Wins: 171689\n",
      "Ties: 142719\n",
      "\n",
      "Episode 660000 done\n",
      "epsilon: 0.076\n",
      "X Wins: 344486\n",
      "O Wins: 172660\n",
      "Ties: 142854\n",
      "\n",
      "Episode 670000 done\n",
      "epsilon: 0.071\n",
      "X Wins: 353201\n",
      "O Wins: 173701\n",
      "Ties: 143098\n",
      "\n",
      "Episode 680000 done\n",
      "epsilon: 0.066\n",
      "X Wins: 362016\n",
      "O Wins: 174617\n",
      "Ties: 143367\n",
      "\n",
      "Episode 690000 done\n",
      "epsilon: 0.062\n",
      "X Wins: 371121\n",
      "O Wins: 175401\n",
      "Ties: 143478\n",
      "\n",
      "Episode 700000 done\n",
      "epsilon: 0.057\n",
      "X Wins: 380020\n",
      "O Wins: 176233\n",
      "Ties: 143747\n",
      "\n",
      "Episode 710000 done\n",
      "epsilon: 0.053\n",
      "X Wins: 389180\n",
      "O Wins: 176940\n",
      "Ties: 143880\n",
      "\n",
      "Episode 720000 done\n",
      "epsilon: 0.050\n",
      "X Wins: 398369\n",
      "O Wins: 177651\n",
      "Ties: 143980\n",
      "\n",
      "Episode 730000 done\n",
      "epsilon: 0.046\n",
      "X Wins: 407506\n",
      "O Wins: 178373\n",
      "Ties: 144121\n",
      "\n",
      "Episode 740000 done\n",
      "epsilon: 0.043\n",
      "X Wins: 416771\n",
      "O Wins: 179043\n",
      "Ties: 144186\n",
      "\n",
      "Episode 750000 done\n",
      "epsilon: 0.040\n",
      "X Wins: 425939\n",
      "O Wins: 179757\n",
      "Ties: 144304\n",
      "\n",
      "Episode 760000 done\n",
      "epsilon: 0.037\n",
      "X Wins: 435165\n",
      "O Wins: 180392\n",
      "Ties: 144443\n",
      "\n",
      "Episode 770000 done\n",
      "epsilon: 0.035\n",
      "X Wins: 444411\n",
      "O Wins: 180995\n",
      "Ties: 144594\n",
      "\n",
      "Episode 780000 done\n",
      "epsilon: 0.032\n",
      "X Wins: 453726\n",
      "O Wins: 181540\n",
      "Ties: 144734\n",
      "\n",
      "Episode 790000 done\n",
      "epsilon: 0.030\n",
      "X Wins: 463160\n",
      "O Wins: 181996\n",
      "Ties: 144844\n",
      "\n",
      "Episode 800000 done\n",
      "epsilon: 0.028\n",
      "X Wins: 472659\n",
      "O Wins: 182421\n",
      "Ties: 144920\n",
      "\n",
      "Episode 810000 done\n",
      "epsilon: 0.026\n",
      "X Wins: 482175\n",
      "O Wins: 182840\n",
      "Ties: 144985\n",
      "\n",
      "Episode 820000 done\n",
      "epsilon: 0.024\n",
      "X Wins: 491698\n",
      "O Wins: 183252\n",
      "Ties: 145050\n",
      "\n",
      "Episode 830000 done\n",
      "epsilon: 0.023\n",
      "X Wins: 501316\n",
      "O Wins: 183570\n",
      "Ties: 145114\n",
      "\n",
      "Episode 840000 done\n",
      "epsilon: 0.021\n",
      "X Wins: 511004\n",
      "O Wins: 183855\n",
      "Ties: 145141\n",
      "\n",
      "Episode 850000 done\n",
      "epsilon: 0.020\n",
      "X Wins: 520688\n",
      "O Wins: 184140\n",
      "Ties: 145172\n",
      "\n",
      "Episode 860000 done\n",
      "epsilon: 0.018\n",
      "X Wins: 530375\n",
      "O Wins: 184427\n",
      "Ties: 145198\n",
      "\n",
      "Episode 870000 done\n",
      "epsilon: 0.017\n",
      "X Wins: 540127\n",
      "O Wins: 184647\n",
      "Ties: 145226\n",
      "\n",
      "Episode 880000 done\n",
      "epsilon: 0.016\n",
      "X Wins: 549877\n",
      "O Wins: 184874\n",
      "Ties: 145249\n",
      "\n",
      "Episode 890000 done\n",
      "epsilon: 0.015\n",
      "X Wins: 559633\n",
      "O Wins: 185066\n",
      "Ties: 145301\n",
      "\n",
      "Episode 900000 done\n",
      "epsilon: 0.014\n",
      "X Wins: 569473\n",
      "O Wins: 185218\n",
      "Ties: 145309\n",
      "\n",
      "Episode 910000 done\n",
      "epsilon: 0.013\n",
      "X Wins: 579285\n",
      "O Wins: 185385\n",
      "Ties: 145330\n",
      "\n",
      "Episode 920000 done\n",
      "epsilon: 0.012\n",
      "X Wins: 589078\n",
      "O Wins: 185562\n",
      "Ties: 145360\n",
      "\n",
      "Episode 930000 done\n",
      "epsilon: 0.011\n",
      "X Wins: 598861\n",
      "O Wins: 185751\n",
      "Ties: 145388\n",
      "\n",
      "Episode 940000 done\n",
      "epsilon: 0.010\n",
      "X Wins: 608605\n",
      "O Wins: 185957\n",
      "Ties: 145438\n",
      "\n",
      "Episode 950000 done\n",
      "epsilon: 0.010\n",
      "X Wins: 618420\n",
      "O Wins: 186131\n",
      "Ties: 145449\n",
      "\n",
      "Episode 960000 done\n",
      "epsilon: 0.009\n",
      "X Wins: 628281\n",
      "O Wins: 186254\n",
      "Ties: 145465\n",
      "\n",
      "Episode 970000 done\n",
      "epsilon: 0.008\n",
      "X Wins: 638111\n",
      "O Wins: 186416\n",
      "Ties: 145473\n",
      "\n",
      "Episode 980000 done\n",
      "epsilon: 0.008\n",
      "X Wins: 647968\n",
      "O Wins: 186540\n",
      "Ties: 145492\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_wins_arr, o_wins_arr, ties_arr = train(X_player, O_player, env, num_episodes, lr, epsilon_decay, gamma, start_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env = TicTacToeEnvironment()\n",
    "state = test_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##policies\n",
    "# X_player = np.zeros((3**9, 9))\n",
    "# O_player = np.zeros((3**9, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env.reset()\n",
    "test_env.play_against_policy(O_player, mode='X', deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env.reset()\n",
    "test_env.play_against_policy(X_player, mode='O', deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(O_player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(O_player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(X_player[encoding_to_idx('0100111100')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_to_idx('100000000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O_player[encoding_to_idx('01000001111')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(O_player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_player[encoding_to_idx('121212000')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_player[encoding_to_idx('121212100')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_player[encoding_to_idx('121212000')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
